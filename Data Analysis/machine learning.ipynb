{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb6137dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)\n",
    "import patsy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "784ca51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceleration_x</th>\n",
       "      <th>acceleration_y</th>\n",
       "      <th>acceleration_z</th>\n",
       "      <th>gyroscope_x</th>\n",
       "      <th>gyroscope_y</th>\n",
       "      <th>gyroscope_z</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.8142</td>\n",
       "      <td>-0.1233</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>3.5095</td>\n",
       "      <td>-6.8665</td>\n",
       "      <td>-2.0370</td>\n",
       "      <td>2024-02-12 15:49:19.455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.8208</td>\n",
       "      <td>-0.1052</td>\n",
       "      <td>-0.0088</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>-8.7204</td>\n",
       "      <td>-3.0060</td>\n",
       "      <td>2024-02-12 15:49:19.455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.8091</td>\n",
       "      <td>-0.0869</td>\n",
       "      <td>-0.0156</td>\n",
       "      <td>7.8964</td>\n",
       "      <td>-10.4675</td>\n",
       "      <td>-3.7079</td>\n",
       "      <td>2024-02-12 15:49:19.479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.8081</td>\n",
       "      <td>-0.0840</td>\n",
       "      <td>-0.0071</td>\n",
       "      <td>8.1787</td>\n",
       "      <td>-8.5449</td>\n",
       "      <td>-4.3106</td>\n",
       "      <td>2024-02-12 15:49:19.495</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.8096</td>\n",
       "      <td>-0.0718</td>\n",
       "      <td>-0.0176</td>\n",
       "      <td>7.3242</td>\n",
       "      <td>-1.0223</td>\n",
       "      <td>-5.5161</td>\n",
       "      <td>2024-02-12 15:49:19.511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.7458</td>\n",
       "      <td>-0.1482</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>-12.3215</td>\n",
       "      <td>38.1546</td>\n",
       "      <td>-28.6942</td>\n",
       "      <td>2024-02-12 15:49:21.167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.9395</td>\n",
       "      <td>-0.1025</td>\n",
       "      <td>0.1331</td>\n",
       "      <td>-4.7455</td>\n",
       "      <td>28.0228</td>\n",
       "      <td>-32.7148</td>\n",
       "      <td>2024-02-12 15:49:21.191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.9331</td>\n",
       "      <td>-0.1370</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.7858</td>\n",
       "      <td>8.7280</td>\n",
       "      <td>-20.8969</td>\n",
       "      <td>2024-02-12 15:49:21.207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.7339</td>\n",
       "      <td>-0.1987</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>-0.9308</td>\n",
       "      <td>4.7531</td>\n",
       "      <td>-9.0637</td>\n",
       "      <td>2024-02-12 15:49:21.231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.5647</td>\n",
       "      <td>-0.1716</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>-3.2959</td>\n",
       "      <td>18.0206</td>\n",
       "      <td>-8.7280</td>\n",
       "      <td>2024-02-12 15:49:21.239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    acceleration_x  acceleration_y  acceleration_z  gyroscope_x  gyroscope_y  \\\n",
       "0          -0.8142         -0.1233         -0.0125       3.5095      -6.8665   \n",
       "1          -0.8208         -0.1052         -0.0088       6.0196      -8.7204   \n",
       "2          -0.8091         -0.0869         -0.0156       7.8964     -10.4675   \n",
       "3          -0.8081         -0.0840         -0.0071       8.1787      -8.5449   \n",
       "4          -0.8096         -0.0718         -0.0176       7.3242      -1.0223   \n",
       "..             ...             ...             ...          ...          ...   \n",
       "95         -0.7458         -0.1482          0.0122     -12.3215      38.1546   \n",
       "96         -0.9395         -0.1025          0.1331      -4.7455      28.0228   \n",
       "97         -0.9331         -0.1370          0.0298       0.7858       8.7280   \n",
       "98         -0.7339         -0.1987         -0.0046      -0.9308       4.7531   \n",
       "99         -0.5647         -0.1716          0.0115      -3.2959      18.0206   \n",
       "\n",
       "    gyroscope_z                timestamp  label  \n",
       "0       -2.0370  2024-02-12 15:49:19.455      1  \n",
       "1       -3.0060  2024-02-12 15:49:19.455      1  \n",
       "2       -3.7079  2024-02-12 15:49:19.479      1  \n",
       "3       -4.3106  2024-02-12 15:49:19.495      1  \n",
       "4       -5.5161  2024-02-12 15:49:19.511      1  \n",
       "..          ...                      ...    ...  \n",
       "95     -28.6942  2024-02-12 15:49:21.167      1  \n",
       "96     -32.7148  2024-02-12 15:49:21.191      1  \n",
       "97     -20.8969  2024-02-12 15:49:21.207      1  \n",
       "98      -9.0637  2024-02-12 15:49:21.231      1  \n",
       "99      -8.7280  2024-02-12 15:49:21.239      1  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "#Uncomment and set the path to the csv file below\n",
    "#file_path_jump = r'D:\\visual studio code\\project\\EEN210-main\\EEN210-main\\repeated_jumping_20240205_155636.csv'\n",
    "file_path_updown =r'D:\\visual studio code\\project\\EEN210-main\\EEN210-main\\sitting up and down 2min.csv'\n",
    "file_path_walk=r'D:\\visual studio code\\project\\EEN210-main\\EEN210-main\\walk_2min_data_20240212_154122.csv'\n",
    "file_path_fall=r'D:\\visual studio code\\project\\EEN210-main\\EEN210-main\\5bagtoss_20240211_203142.csv'\n",
    "\n",
    "\n",
    "walk_data = pd.read_csv(file_path_walk)\n",
    "updown_data = pd.read_csv(file_path_updown)\n",
    "#stand_data=pd.read_csv(file_path_stand)\n",
    "fall_data=pd.read_csv(file_path_fall)\n",
    "\n",
    "walk_data[\"label\"]=0\n",
    "updown_data[\"label\"]=1\n",
    "fall_data[\"label\"]=2\n",
    "updown_data.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88b4d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "        \"acceleration_x\",\n",
    "        \"acceleration_y\",\n",
    "        \"acceleration_z\",\n",
    "        \"gyroscope_x\",\n",
    "        \"gyroscope_y\",\n",
    "        \"gyroscope_z\",\n",
    "    ]\n",
    "\n",
    "data = pd.concat([walk_data, updown_data, fall_data])\n",
    "\n",
    "# Preprocess the data\n",
    "X = data.drop(['timestamp', 'label'], axis=1)  # Features\n",
    "y = data['label']  # Target labels\n",
    "\n",
    "# Convert the DataFrame to numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e23b7a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.25062482  0.09098766  0.58453704 -1.27310754  0.78888969  0.39777123]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "#print(X_train[0])\n",
    "normalizer = StandardScaler()\n",
    "\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74ba236c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 95.08521601268332\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94      1863\n",
      "           1       0.96      0.96      0.96      2071\n",
      "           2       0.98      0.94      0.96      1112\n",
      "\n",
      "    accuracy                           0.95      5046\n",
      "   macro avg       0.96      0.95      0.95      5046\n",
      "weighted avg       0.95      0.95      0.95      5046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 25, class_weight=\"balanced\")\n",
    "# Fitting model\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "#Model accuracy\n",
    "acc = accuracy_score(y_test, pred)*100\n",
    "print('accuracy_score',acc)\n",
    "\n",
    "# Classification Report\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "837d339f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.9937820112457462\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, plot_roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you've already prepared your data X_train, X_test, y_train, y_test\n",
    "\n",
    "# Preprocess the data\n",
    "normalizer = StandardScaler()\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=25, class_weight=\"balanced\")\n",
    "rf_classifier.fit(X_train,y_train)\n",
    "\n",
    "# Create OneVsRestClassifier\n",
    "#ovr_classifier = OneVsRestClassifier(rf_classifier)\n",
    "\n",
    "# Fit the model\n",
    "#ovr_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict_proba(X_test)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred, multi_class='ovr')\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "\n",
    "# Plot ROC curve\n",
    "#plot_roc_curve(rf_classifier, X_test, y_pred)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7c5b000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(3):  # Assuming you have 3 classes\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test == i, y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure()\n",
    "lw = 2\n",
    "colors = ['blue', 'red', 'green']  # Colors for each class\n",
    "for i, color in zip(range(3), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7ae6478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.95031847 0.94734607 0.94989384 0.94904459 0.94562447]\n",
      "Mean cross-validation score: 0.9484454882776211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=25, class_weight=\"balanced\")\n",
    "rf_classifier.fit(X_train,y_train)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(rf_classifier, X_train, y_train, cv=5)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e3c23c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.91974522 0.91592357 0.91549894 0.91125265 0.91461342]\n",
      "Mean cross-validation score: 0.9154067612249646\n",
      "accuracy_score 92.2116527942925\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90      1835\n",
      "           1       0.94      0.93      0.93      2131\n",
      "           2       0.94      0.94      0.94      1080\n",
      "\n",
      "    accuracy                           0.92      5046\n",
      "   macro avg       0.92      0.92      0.92      5046\n",
      "weighted avg       0.92      0.92      0.92      5046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the DecisionTreeClassifier\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(dt_classifier, X_train, y_train, cv=5)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "dt_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "#Model accuracy\n",
    "acc = accuracy_score(y_test, dt_pred)*100\n",
    "print('accuracy_score',acc)\n",
    "\n",
    "# Classification Report\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, dt_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ee2aa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9431232659532303\n",
      "Precision: 0.9433291575857516\n",
      "Recall: 0.9431232659532303\n",
      "F1-score: 0.9430575036981231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize the GradientBoostingClassifier\n",
    "gb_classifier = GradientBoostingClassifier()\n",
    "\n",
    "# Fit the model\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf9ed4dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-2975219f9ad8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Define the neural network architecture\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m model = tf.keras.Sequential([\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # 3 output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = tf.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56c4f5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 170.5889751315117\n",
      "Epoch [2/10], Loss: 136.07326459884644\n",
      "Epoch [3/10], Loss: 125.5069934129715\n",
      "Epoch [4/10], Loss: 121.77771800756454\n",
      "Epoch [5/10], Loss: 119.99202877283096\n",
      "Epoch [6/10], Loss: 118.8799352645874\n",
      "Epoch [7/10], Loss: 118.11589056253433\n",
      "Epoch [8/10], Loss: 117.54746544361115\n",
      "Epoch [9/10], Loss: 117.09511238336563\n",
      "Epoch [10/10], Loss: 116.74123787879944\n",
      "Accuracy on test set: 0.9223147047166073\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Define the neural network architecture\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss}\")\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy on test set: {accuracy}\")\n",
    "\n",
    "# Load your data and preprocess it\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "#print(X_train[0])\n",
    "normalizer = StandardScaler()\n",
    "\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "#Create DataLoader objects\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64\n",
    "num_classes = len(np.unique(y_train))\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Create the neural network model\n",
    "model_NN = NeuralNetwork(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_NN.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(model_NN, train_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model_NN, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4e4e101",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-02ca0e1b3e59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;31m# Train the LSTM model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m \u001b[0mtrain_lstm_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_lstm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m# Evaluate the LSTM model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-02ca0e1b3e59>\u001b[0m in \u001b[0;36mtrain_lstm_model\u001b[1;34m(model, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-02ca0e1b3e59>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mc0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    687\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    630\u001b[0m                            \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m                            ):\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[0;32m    634\u001b[0m                                'Expected hidden[0] size {}, got {}')\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0mexpected_input_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mexpected_input_dim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m    202\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[0;32m    203\u001b[0m                     expected_input_dim, input.dim()))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Function to train the LSTM model\n",
    "def train_lstm_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss}\")\n",
    "\n",
    "# Function to evaluate the LSTM model\n",
    "def evaluate_lstm_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy on test set: {accuracy}\")\n",
    "\n",
    "# Load your data and preprocess it\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)  # Assuming y is a pandas Series\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = 6 # Example input size\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "num_classes = 3 # Example number of classes\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Create the LSTM model\n",
    "model_lstm = LSTMClassifier(input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the LSTM model\n",
    "train_lstm_model(model_lstm, train_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Evaluate the LSTM model\n",
    "evaluate_lstm_model(model_lstm, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf3c968a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n",
      "Model loaded successfully.\n",
      "Predicted label: [0 0 0 ... 0 0 0]\n",
      "6443\n",
      "Accuracy for label 0: 92.31%\n",
      "Model saved successfully.\n",
      "Model loaded successfully.\n",
      "Predicted label: [0 0 0 ... 0 0 0]\n",
      "6110\n",
      "Accuracy for label 0: 87.54%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "def save_model(model, filename):\n",
    "    try:\n",
    "        joblib.dump(model, filename)\n",
    "        print(\"Model saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error saving model:\", e)\n",
    "\n",
    "def load_model(filename):\n",
    "    try:\n",
    "        model = joblib.load(filename)\n",
    "        print(\"Model loaded successfully.\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(\"Error loading model:\", e)\n",
    "        return None\n",
    "\n",
    "def train_model(method, X_train, y_train):\n",
    "    if method == 'RandomForest':\n",
    "        model = RandomForestClassifier(n_estimators = 25, class_weight=\"balanced\")\n",
    "    elif method == 'DecisionTree':\n",
    "        model = DecisionTreeClassifier()\n",
    "    elif method == 'SVM':\n",
    "        model = SVC()\n",
    "    elif method =='GradientBoost':\n",
    "        model== GradientBoostingClassifier()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid machine learning method specified.\")\n",
    "    \n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(\"Error training model:\", e)\n",
    "        return None\n",
    "\n",
    "def predict_label(model, data):\n",
    "    try:\n",
    "        label = model.predict(data)\n",
    "        return label\n",
    "    except Exception as e:\n",
    "        print(\"Error predicting label:\", e)\n",
    "        return None\n",
    "\n",
    "def predict_label_NN(model, data):\n",
    "    try:\n",
    "        # Convert data to tensor\n",
    "        data_tensor = torch.tensor(data.values, dtype=torch.float32)\n",
    "        \n",
    "        # Make predictions using the model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(data_tensor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        return predicted.numpy()  # Convert predictions to numpy array\n",
    "    except Exception as e:\n",
    "        print(\"Error predicting label:\", e)\n",
    "        return None\n",
    "\n",
    "def calculate_accuracy(true_labels, predicted_labels):\n",
    "    # Count the occurrences of the target label in the true labels\n",
    "    correct_target_labels = np.sum(predicted_labels==true_labels)\n",
    "    print(correct_target_labels)\n",
    "    \n",
    "    # Count the occurrences of the target label in the predicted labels\n",
    "    #correct_predicted_labels = sum((true_labels == target_label) & (predicted_labels == target_label))\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    if correct_target_labels > 0:\n",
    "        accuracy = (correct_target_labels / len(predicted_labels)) * 100\n",
    "    else:\n",
    "        accuracy = 0\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Train the model\n",
    "# model = train_model()\n",
    "method = 'RandomForest'\n",
    "\n",
    "trained_model = train_model(method, X_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "save_model(trained_model, \"model.pkl\")\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = load_model(\"model.pkl\")\n",
    "\n",
    "# Example prediction\n",
    "file_path=r'D:\\visual studio code\\project\\EEN210-main\\EEN210-main\\fall_on_back_data_20240211_195608.csv'\n",
    "\n",
    "#file_path_jump = r'D:\\visual studio code\\project\\EEN210-main\\EEN210-main\\repeated_jumping_20240205_155636.csv'\n",
    "file_path_updown =r'D:\\visual studio code\\project\\EEN210-main\\EEN210-main\\sitting up and down 2min.csv'\n",
    "#file_path_stand=r'D:\\visual studio code\\project\\EEN210-main\\EEN210-main\\standing_20240205_155041.csv'\n",
    "\n",
    "target_label = 0\n",
    "data = pd.read_csv(file_path_updown)\n",
    "X = data.drop(['timestamp', 'label'], axis=1)  # Features\n",
    "y = data['label']\n",
    "#np.set_printoptions(threshold=np.inf) \n",
    "np.set_printoptions(threshold=20) \n",
    "# data = ... # Load or generate your data here\n",
    "label = predict_label(loaded_model, X)\n",
    "print(\"Predicted label:\", label)\n",
    "accuracy_label = calculate_accuracy(target_label, label)\n",
    "print(f\"Accuracy for label {target_label}: {accuracy_label:.2f}%\")\n",
    "# Save the trained model\n",
    "save_model(model_NN, \"model_NN.pkl\")\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = load_model(\"model_NN.pkl\")\n",
    "label = predict_label_NN(loaded_model, X)\n",
    "print(\"Predicted label:\", label)\n",
    "# Calculate the accuracy for label 2\n",
    "accuracy_label = calculate_accuracy(target_label, label)\n",
    "print(f\"Accuracy for label {target_label}: {accuracy_label:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
