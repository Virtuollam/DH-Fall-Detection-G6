{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb6137dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)\n",
    "import patsy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "784ca51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceleration_x</th>\n",
       "      <th>acceleration_y</th>\n",
       "      <th>acceleration_z</th>\n",
       "      <th>gyroscope_x</th>\n",
       "      <th>gyroscope_y</th>\n",
       "      <th>gyroscope_z</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.8142</td>\n",
       "      <td>-0.1233</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>3.5095</td>\n",
       "      <td>-6.8665</td>\n",
       "      <td>-2.0370</td>\n",
       "      <td>2024-02-12 15:49:19.455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.8208</td>\n",
       "      <td>-0.1052</td>\n",
       "      <td>-0.0088</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>-8.7204</td>\n",
       "      <td>-3.0060</td>\n",
       "      <td>2024-02-12 15:49:19.455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.8091</td>\n",
       "      <td>-0.0869</td>\n",
       "      <td>-0.0156</td>\n",
       "      <td>7.8964</td>\n",
       "      <td>-10.4675</td>\n",
       "      <td>-3.7079</td>\n",
       "      <td>2024-02-12 15:49:19.479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.8081</td>\n",
       "      <td>-0.0840</td>\n",
       "      <td>-0.0071</td>\n",
       "      <td>8.1787</td>\n",
       "      <td>-8.5449</td>\n",
       "      <td>-4.3106</td>\n",
       "      <td>2024-02-12 15:49:19.495</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.8096</td>\n",
       "      <td>-0.0718</td>\n",
       "      <td>-0.0176</td>\n",
       "      <td>7.3242</td>\n",
       "      <td>-1.0223</td>\n",
       "      <td>-5.5161</td>\n",
       "      <td>2024-02-12 15:49:19.511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.7458</td>\n",
       "      <td>-0.1482</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>-12.3215</td>\n",
       "      <td>38.1546</td>\n",
       "      <td>-28.6942</td>\n",
       "      <td>2024-02-12 15:49:21.167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.9395</td>\n",
       "      <td>-0.1025</td>\n",
       "      <td>0.1331</td>\n",
       "      <td>-4.7455</td>\n",
       "      <td>28.0228</td>\n",
       "      <td>-32.7148</td>\n",
       "      <td>2024-02-12 15:49:21.191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.9331</td>\n",
       "      <td>-0.1370</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.7858</td>\n",
       "      <td>8.7280</td>\n",
       "      <td>-20.8969</td>\n",
       "      <td>2024-02-12 15:49:21.207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.7339</td>\n",
       "      <td>-0.1987</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>-0.9308</td>\n",
       "      <td>4.7531</td>\n",
       "      <td>-9.0637</td>\n",
       "      <td>2024-02-12 15:49:21.231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.5647</td>\n",
       "      <td>-0.1716</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>-3.2959</td>\n",
       "      <td>18.0206</td>\n",
       "      <td>-8.7280</td>\n",
       "      <td>2024-02-12 15:49:21.239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    acceleration_x  acceleration_y  acceleration_z  gyroscope_x  gyroscope_y  \\\n",
       "0          -0.8142         -0.1233         -0.0125       3.5095      -6.8665   \n",
       "1          -0.8208         -0.1052         -0.0088       6.0196      -8.7204   \n",
       "2          -0.8091         -0.0869         -0.0156       7.8964     -10.4675   \n",
       "3          -0.8081         -0.0840         -0.0071       8.1787      -8.5449   \n",
       "4          -0.8096         -0.0718         -0.0176       7.3242      -1.0223   \n",
       "..             ...             ...             ...          ...          ...   \n",
       "95         -0.7458         -0.1482          0.0122     -12.3215      38.1546   \n",
       "96         -0.9395         -0.1025          0.1331      -4.7455      28.0228   \n",
       "97         -0.9331         -0.1370          0.0298       0.7858       8.7280   \n",
       "98         -0.7339         -0.1987         -0.0046      -0.9308       4.7531   \n",
       "99         -0.5647         -0.1716          0.0115      -3.2959      18.0206   \n",
       "\n",
       "    gyroscope_z                timestamp  label  \n",
       "0       -2.0370  2024-02-12 15:49:19.455      1  \n",
       "1       -3.0060  2024-02-12 15:49:19.455      1  \n",
       "2       -3.7079  2024-02-12 15:49:19.479      1  \n",
       "3       -4.3106  2024-02-12 15:49:19.495      1  \n",
       "4       -5.5161  2024-02-12 15:49:19.511      1  \n",
       "..          ...                      ...    ...  \n",
       "95     -28.6942  2024-02-12 15:49:21.167      1  \n",
       "96     -32.7148  2024-02-12 15:49:21.191      1  \n",
       "97     -20.8969  2024-02-12 15:49:21.207      1  \n",
       "98      -9.0637  2024-02-12 15:49:21.231      1  \n",
       "99      -8.7280  2024-02-12 15:49:21.239      1  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "#Uncomment and set the path to the csv file below\n",
    "#file_path_jump = r'D:\\visual studio code\\project\\EEN210-main\\EEN210-main\\repeated_jumping_20240205_155636.csv'\n",
    "file_path_updown =r'D:\\visual studio code\\project\\EEN210-main\\EEN210-main\\sitting up and down 2min.csv'\n",
    "file_path_walk=r'D:\\visual studio code\\project\\EEN210-main\\EEN210-main\\walk_2min_data_20240212_154122.csv'\n",
    "file_path_fall=r'D:\\visual studio code\\project\\EEN210-main\\EEN210-main\\5bagtoss_20240211_203142.csv'\n",
    "\n",
    "\n",
    "walk_data = pd.read_csv(file_path_walk)\n",
    "updown_data = pd.read_csv(file_path_updown)\n",
    "#stand_data=pd.read_csv(file_path_stand)\n",
    "fall_data=pd.read_csv(file_path_fall)\n",
    "\n",
    "walk_data[\"label\"]=0\n",
    "updown_data[\"label\"]=1\n",
    "fall_data[\"label\"]=2\n",
    "updown_data.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88b4d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "        \"acceleration_x\",\n",
    "        \"acceleration_y\",\n",
    "        \"acceleration_z\",\n",
    "        \"gyroscope_x\",\n",
    "        \"gyroscope_y\",\n",
    "        \"gyroscope_z\",\n",
    "    ]\n",
    "\n",
    "data = pd.concat([walk_data, updown_data, fall_data])\n",
    "\n",
    "# Preprocess the data\n",
    "X = data.drop(['timestamp', 'label'], axis=1)  # Features\n",
    "y = data['label']  # Target labels\n",
    "\n",
    "# Convert the DataFrame to numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e23b7a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.25062482  0.09098766  0.58453704 -1.27310754  0.78888969  0.39777123]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "#print(X_train[0])\n",
    "normalizer = StandardScaler()\n",
    "\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf9ed4dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-2975219f9ad8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Define the neural network architecture\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m model = tf.keras.Sequential([\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # 3 output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = tf.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56c4f5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 168.29856592416763\n",
      "Epoch [2/10], Loss: 133.96286988258362\n",
      "Epoch [3/10], Loss: 124.84278094768524\n",
      "Epoch [4/10], Loss: 121.49272096157074\n",
      "Epoch [5/10], Loss: 119.7707439661026\n",
      "Epoch [6/10], Loss: 118.73235285282135\n",
      "Epoch [7/10], Loss: 117.98577731847763\n",
      "Epoch [8/10], Loss: 117.47499591112137\n",
      "Epoch [9/10], Loss: 117.04709595441818\n",
      "Epoch [10/10], Loss: 116.69656324386597\n",
      "Accuracy on test set: 0.9244946492271106\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Define the neural network architecture\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss}\")\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy on test set: {accuracy}\")\n",
    "\n",
    "# Load your data and preprocess it\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "#Create DataLoader objects\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64\n",
    "num_classes = len(np.unique(y_train))\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Create the neural network model\n",
    "model_NN = NeuralNetwork(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_NN.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(model_NN, train_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model_NN, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4e4e101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16771, 50, 6)\n",
      "Epoch [1/10], Loss: 55.75095129292458\n",
      "Epoch [2/10], Loss: 7.819618345238268\n",
      "Epoch [3/10], Loss: 7.393310149433091\n",
      "Epoch [4/10], Loss: 3.996404674369842\n",
      "Epoch [5/10], Loss: 0.9487196463742293\n",
      "Epoch [6/10], Loss: 0.6281467087683268\n",
      "Epoch [7/10], Loss: 0.4861428744334262\n",
      "Epoch [8/10], Loss: 0.27536201509064995\n",
      "Epoch [9/10], Loss: 0.17382752822595648\n",
      "Epoch [10/10], Loss: 0.14423761586658657\n",
      "Accuracy on test set: 1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Function to train the LSTM model\n",
    "def train_lstm_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss}\")\n",
    "\n",
    "# Function to evaluate the LSTM model\n",
    "def evaluate_lstm_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy on test set: {accuracy}\")\n",
    "\n",
    "window_length = 50\n",
    "num_features = 6  # Number of features in your data\n",
    "\n",
    "# Define a function to reshape your data\n",
    "def reshape_data(data, window_length):\n",
    "    num_samples, num_features = data.shape\n",
    "    num_windows = num_samples - window_length + 1\n",
    "    reshaped_data = np.zeros((num_windows, window_length, num_features))\n",
    "    for i in range(num_windows):\n",
    "        window = data[i:i+window_length, :]\n",
    "        reshaped_data[i] = window\n",
    "    return reshaped_data\n",
    "\n",
    "# Reshape your data\n",
    "X_ = reshape_data(X.values, window_length)\n",
    "print(X_.shape)  # Output should be (num_sequences, time_length, num_features)\n",
    "\n",
    "y_ = y[window_length-1:] \n",
    "\n",
    "\n",
    "\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, y_, test_size=0.3)\n",
    "\n",
    "# Load your data and preprocess it\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_.values.astype(int), dtype=torch.long)  # Assuming y is a pandas Series\n",
    "y_test_tensor = torch.tensor(y_test_.values.astype(int), dtype=torch.long)\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = 6 # Example input size\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "num_classes = 3 # Example number of classes\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Create the LSTM model\n",
    "model_lstm = LSTMClassifier(input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the LSTM model\n",
    "train_lstm_model(model_lstm, train_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Evaluate the LSTM model\n",
    "evaluate_lstm_model(model_lstm, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16771, 50, 6)\n",
      "[0.92628432 0.79948394 1.49340436]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "number of dims don't match in permute",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e346da7f2075>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[0mX_test_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[0my_test_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[0mX_train_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[0my_train_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-e346da7f2075>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x_train, y_train, x_val, y_val, epochs, verbose, plot, lr, weight_decay)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[1;31m# Training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-e346da7f2075>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: number of dims don't match in permute"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def calc_accuracy(pred_y, y):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return ((pred_y == y).sum() / len(y)).item()\n",
    "\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, target_size, batch_size=10, dropout=0.5):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.norm_layer = nn.BatchNorm1d(\n",
    "            input_dim, affine=True, track_running_stats=False\n",
    "        )\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, target_size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, input_):\n",
    "        x = self.norm_layer(input_.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        lstm_out, (h, c) = self.lstm(x)\n",
    "        logits = self.fc(lstm_out[:, -1])\n",
    "        logits = self.dropout(logits)\n",
    "        scores = F.softmax(logits, dim=1)\n",
    "        return scores\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        x_val=None,\n",
    "        y_val=None,\n",
    "        epochs=1,\n",
    "        verbose=False,\n",
    "        plot=False,\n",
    "        lr=1e-4,\n",
    "        weight_decay=5e-5,\n",
    "    ):\n",
    "        trainloader = DataLoader(\n",
    "            TensorDataset(x_train, y_train), batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "        class_weights = compute_class_weight(\n",
    "            class_weight=\"balanced\", classes=np.unique(y_train), y=y_train.numpy()\n",
    "        )\n",
    "        print(class_weights)\n",
    "        class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "        criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        # criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "        )\n",
    "\n",
    "        batch_acc_list = []\n",
    "        train_acc_list = []\n",
    "        val_acc_list = []\n",
    "        batch_loss_list = []\n",
    "        train_loss_list = []\n",
    "        val_loss_list = []\n",
    "        for epoch in range(epochs + 1):\n",
    "            losses = []\n",
    "            accuracies = []\n",
    "            self.train()\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "                # Training\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = self(inputs)\n",
    "                loss = criterion(y_pred, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses.append(loss.detach().numpy())\n",
    "                batch_acc = calc_accuracy(y_pred.argmax(dim=1), labels)\n",
    "                accuracies.append(batch_acc)\n",
    "            avg_loss = np.mean(losses)\n",
    "            avg_accuracy = np.mean(accuracies)\n",
    "\n",
    "            # Print metrics every 10 epochs\n",
    "            if verbose and x_val is not None:\n",
    "                y_pred_train = self(x_train)\n",
    "                train_loss = criterion(y_pred_train, y_train)\n",
    "                train_acc = calc_accuracy(y_pred_train.argmax(dim=1), y_train)\n",
    "                # f1_score = calc_f1_score(y_pred.argmax(dim=1), y_train)\n",
    "\n",
    "                # Validation\n",
    "                self.eval()\n",
    "                y_pred_val = self(x_val)\n",
    "                val_loss = criterion(y_pred_val, y_val)\n",
    "                val_acc = calc_accuracy(y_pred_val.argmax(dim=1), y_val)\n",
    "                # val_f1_score = calc_f1_score(y_pred_val.argmax(dim=1), y_val)\n",
    "\n",
    "                if epoch % 1 == 0:\n",
    "                    print(\n",
    "                        f\"Epoch {epoch:>3} | Train Loss: {avg_loss:.3f} | Train Acc:\"\n",
    "                        f\" {avg_accuracy*100:>6.2f}% | Val Loss: {val_loss:.2f} | \"\n",
    "                        # f\"F1 Score: {f1_score*100:.2f}% | \"\n",
    "                        f\"Val Acc: {val_acc*100:.2f}% | \",\n",
    "                        # f\"Val F1 Score: {val_f1_score*100:.2f}%\",\n",
    "                        end=\"\\r\",\n",
    "                    )\n",
    "\n",
    "                batch_acc_list.append(avg_accuracy)\n",
    "                train_acc_list.append(train_acc)\n",
    "                val_acc_list.append(val_acc)\n",
    "                batch_loss_list.append(avg_loss)\n",
    "                train_loss_list.append(train_loss.detach().numpy())\n",
    "                val_loss_list.append(val_loss.detach().numpy())\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\n\")\n",
    "\n",
    "        if plot:\n",
    "            plt.figure()\n",
    "            plt.plot(batch_acc_list, label=\"batch\")\n",
    "            # plt.plot(train_acc_list, label=\"train\")\n",
    "            plt.plot(val_acc_list, label=\"val\")\n",
    "            plt.xlabel(\"epochs\")\n",
    "            plt.title(\"accuracy\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(batch_loss_list, label=\"batch\")\n",
    "            # plt.plot(train_loss_list, label=\"train\")\n",
    "            plt.plot(val_loss_list, label=\"val\")\n",
    "            plt.xlabel(\"epochs\")\n",
    "            plt.title(\"loss\")\n",
    "            plt.legend()\n",
    "\n",
    "        if x_val is not None:\n",
    "            self.eval()\n",
    "            y_pred_val = self(x_val)\n",
    "            val_loss = criterion(y_pred_val, y_val)\n",
    "            val_acc = calc_accuracy(y_pred_val.argmax(dim=1), y_val)\n",
    "\n",
    "            print(\n",
    "                classification_report(\n",
    "                    y_val.numpy(), y_pred_val.detach().argmax(dim=1).numpy()\n",
    "                )\n",
    "            )\n",
    "\n",
    "            return val_acc, val_loss\n",
    "        \n",
    "#\n",
    "window_length = 50\n",
    "num_features = 6  # Number of features in your data\n",
    "\n",
    "# Define a function to reshape your data\n",
    "def reshape_data(data, window_length):\n",
    "    num_samples, num_features = data.shape\n",
    "    num_windows = num_samples - window_length + 1\n",
    "    reshaped_data = np.zeros((num_windows, window_length, num_features))\n",
    "    for i in range(num_windows):\n",
    "        window = data[i:i+window_length, :]\n",
    "        reshaped_data[i] = window\n",
    "    return reshaped_data\n",
    "\n",
    "# Reshape your data\n",
    "X_ = reshape_data(X.values, window_length)\n",
    "print(X_.shape)  # Output should be (num_sequences, time_length, num_features)\n",
    "\n",
    "y_ = y[window_length-1:] \n",
    "\n",
    "\n",
    "\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, y_, test_size=0.3)\n",
    "\n",
    "model = LSTMNet(X_.shape[2], hidden_dim=10, target_size=2, batch_size=10, dropout=0.1)\n",
    "X_train_tensor = torch.tensor(X_train.astype(np.float32))\n",
    "y_train_tensor = torch.tensor(y_train.values.astype(int))\n",
    "X_test_tensor = torch.tensor(X_test.astype(np.float32))\n",
    "y_test_tensor = torch.tensor(y_test.values.astype(int))\n",
    "model.fit(\n",
    "    X_train_tensor,\n",
    "    y_train_tensor,\n",
    "    X_test_tensor,\n",
    "    y_test_tensor,\n",
    "    epochs=1000,\n",
    "    verbose=True,\n",
    "    plot=True,\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf3c968a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n",
      "Model saved successfully.\n",
      "Model loaded successfully.\n",
      "Model loaded successfully.\n",
      "Predicted label: [2 2 2 ... 2 2 2]\n",
      "5224\n",
      "Accuracy for label 2: 50.62%\n",
      "Model saved successfully.\n",
      "Model loaded successfully.\n",
      "Predicted label: [2 2 2 ... 2 2 2]\n",
      "5491\n",
      "Accuracy for label 2: 53.21%\n",
      "(10271, 50, 6)\n",
      "Model saved successfully.\n",
      "Model loaded successfully.\n",
      "Predicted label: [2 2 2 ... 2 2 2]\n",
      "6745\n",
      "Accuracy for label 2: 65.67%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import joblib\n",
    "#import pickle\n",
    "\n",
    "def save_model(model, filename):\n",
    "    try:\n",
    "        joblib.dump(model, filename)\n",
    "        #pickle.dump(model, filename)\n",
    "        print(\"Model saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error saving model:\", e)\n",
    "\n",
    "def load_model(filename):\n",
    "    try:\n",
    "        #model = pickle.load(filename)\n",
    "        model = joblib.load(filename)\n",
    "        print(\"Model loaded successfully.\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(\"Error loading model:\", e)\n",
    "        return None\n",
    "\n",
    "def train_model(method, X_train, y_train):\n",
    "    if method == 'RandomForest':\n",
    "        model = RandomForestClassifier(n_estimators = 25, class_weight=\"balanced\")\n",
    "    elif method == 'DecisionTree':\n",
    "        model = DecisionTreeClassifier()\n",
    "    elif method == 'SVM':\n",
    "        model = SVC()\n",
    "    elif method =='GradientBoost':\n",
    "        model== GradientBoostingClassifier()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid machine learning method specified.\")\n",
    "    \n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(\"Error training model:\", e)\n",
    "        return None\n",
    "\n",
    "def predict_label(model, data):\n",
    "    try:\n",
    "        label = model.predict(data)\n",
    "        return label\n",
    "    except Exception as e:\n",
    "        print(\"Error predicting label:\", e)\n",
    "        return None\n",
    "\n",
    "def predict_label_NN(model, data):\n",
    "    try:\n",
    "        # Convert data to tensor\n",
    "        data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "        \n",
    "        # Make predictions using the model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(data_tensor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        return predicted.numpy()  # Convert predictions to numpy array\n",
    "    except Exception as e:\n",
    "        print(\"Error predicting label:\", e)\n",
    "        return None\n",
    "\n",
    "def predict_label_LSTM(model, data):\n",
    "    try:\n",
    "        # Convert data to tensor\n",
    "        data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "        \n",
    "        # Make predictions using the model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(data_tensor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        return predicted.numpy()  # Convert predictions to numpy array\n",
    "    except Exception as e:\n",
    "        print(\"Error predicting label:\", e)\n",
    "        return None\n",
    "\n",
    "def calculate_accuracy(true_labels, predicted_labels):\n",
    "    # Count the occurrences of the target label in the true labels\n",
    "    correct_target_labels = np.sum(predicted_labels==true_labels)\n",
    "    print(correct_target_labels)\n",
    "    \n",
    "    # Count the occurrences of the target label in the predicted labels\n",
    "    #correct_predicted_labels = sum((true_labels == target_label) & (predicted_labels == target_label))\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    if correct_target_labels > 0:\n",
    "        accuracy = (correct_target_labels / len(predicted_labels)) * 100\n",
    "    else:\n",
    "        accuracy = 0\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Train the model\n",
    "# model = train_model()\n",
    "method = 'RandomForest'\n",
    "\n",
    "trained_model = train_model(method, X_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "save_model(trained_model, \"model.pkl\")\n",
    "save_model(normalizer, \"normalizer.pkl\")\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = load_model(\"model.pkl\")\n",
    "loaded_norm = load_model(\"normalizer.pkl\")\n",
    "\n",
    "# Example prediction\n",
    "file_path=r'D:\\visual studio code\\project\\EEN210-main\\EEN210-main\\fall_on_back_data_20240211_195608.csv'\n",
    "\n",
    "#file_path_jump = r'D:\\visual studio code\\project\\EEN210-main\\EEN210-main\\repeated_jumping_20240205_155636.csv'\n",
    "file_path_updown =r'D:\\visual studio code\\project\\EEN210-main\\EEN210-main\\sitting up and down 2min.csv'\n",
    "file_path_walk=r'D:\\visual studio code\\project\\EEN210-main\\EEN210-main\\walk_2min_data_20240212_154122.csv'\n",
    "#walk_data[\"label\"]=0 updown_data[\"label\"]=1 fall_data[\"label\"]=2\n",
    "\n",
    "target_label = 2\n",
    "data = pd.read_csv(file_path)  #choose test file here\n",
    "X = data.drop(['timestamp', 'label'], axis=1)  # Features\n",
    "y = data['label']\n",
    "\n",
    "#normalizer = StandardScaler()\n",
    "\n",
    "X = loaded_norm.transform(X)\n",
    "\n",
    "#np.set_printoptions(threshold=np.inf) \n",
    "np.set_printoptions(threshold=20) \n",
    "# data = ... # Load or generate your data here\n",
    "label = predict_label(loaded_model, X)\n",
    "print(\"Predicted label:\", label)\n",
    "accuracy_label = calculate_accuracy(target_label, label)\n",
    "print(f\"Accuracy for label {target_label}: {accuracy_label:.2f}%\")\n",
    "# Save the trained model\n",
    "save_model(model_NN, \"model_NN.pkl\")\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = load_model(\"model_NN.pkl\")\n",
    "label = predict_label_NN(loaded_model, X)\n",
    "print(\"Predicted label:\", label)\n",
    "# Calculate the accuracy for label 2\n",
    "accuracy_label = calculate_accuracy(target_label, label)\n",
    "print(f\"Accuracy for label {target_label}: {accuracy_label:.2f}%\")\n",
    "\n",
    "window_length = 50\n",
    "num_features = 6  # Number of features in your data\n",
    "\n",
    "# Define a function to reshape your data\n",
    "def reshape_data(data, window_length):\n",
    "    num_samples, num_features = data.shape\n",
    "    num_windows = num_samples - window_length + 1\n",
    "    reshaped_data = np.zeros((num_windows, window_length, num_features))\n",
    "    for i in range(num_windows):\n",
    "        window = data[i:i+window_length, :]\n",
    "        reshaped_data[i] = window\n",
    "    return reshaped_data\n",
    "\n",
    "# Reshape your data\n",
    "X_ = reshape_data(X, window_length)\n",
    "print(X_.shape)  # Output should be (num_sequences, time_length, num_features)\n",
    "\n",
    "y_ = y[window_length-1:] \n",
    "\n",
    "save_model(model_lstm, \"model_lstm.pkl\")\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = load_model(\"model_lstm.pkl\")\n",
    "label = predict_label_LSTM(loaded_model, X_)\n",
    "print(\"Predicted label:\", label)\n",
    "# Calculate the accuracy for label 2\n",
    "accuracy_label = calculate_accuracy(target_label, label)\n",
    "print(f\"Accuracy for label {target_label}: {accuracy_label:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
